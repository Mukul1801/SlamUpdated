{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1747660214142
        }
      },
      "outputs": [],
      "source": [
        "DATABRICKS_TOKEN = ''\n",
        "DATABRICKS_HTTP_PATH = \"\"\n",
        "DATABRICKS_SERVER_HOSTNAME =\"\"\n",
        "database = \"\"\n",
        "HOST_HTTP_PATH = \"\"\n",
        "SERVER_NAME =  \"\"\n",
        "warehouse_id = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1747660215603
        }
      },
      "outputs": [],
      "source": [
        "HOST = SERVER_NAME+'/'+HOST_HTTP_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1747660223523
        }
      },
      "outputs": [],
      "source": [
        "from langchain.sql_database import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_databricks(catalog=\"\", schema=\"\", engine_args={\"pool_pre_ping\": True},host=HOST,api_token=DATABRICKS_TOKEN,warehouse_id=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1747660223689
        }
      },
      "outputs": [],
      "source": [
        "def extract_table_metadata(table_name):\n",
        "    describe_output = db.run(f\"DESCRIBE EXTENDED {table_name}\")\n",
        "    processed_output = eval(describe_output) if isinstance(describe_output, str) else describe_output\n",
        "\n",
        "    column_details = []\n",
        "    table_description = \"No description available\"\n",
        "\n",
        "    for row in processed_output:\n",
        "        if row[0].strip().lower() == \"comment\":  # Extract table description\n",
        "            table_description = row[1]\n",
        "        elif (\n",
        "            len(row) == 3  # Ensure valid column format\n",
        "            and row[0].strip()  # Ignore empty column names\n",
        "            and row[0].strip() not in [\"#\", \"\", \"Detailed Table Information\", \"Catalog\", \"Database\", \"Table\", \n",
        "                                       \"Created Time\", \"Last Access\", \"Created By\", \"Type\", \"Location\", \"Provider\", \n",
        "                                       \"Owner\", \"Is_managed_location\", \"Predictive Optimization\", \"Table Properties\"]\n",
        "        ):\n",
        "            column_details.append({\n",
        "                \"name\": row[0], \n",
        "                \"type\": row[1], \n",
        "                \"description\": row[2] if row[2] else \"No description available\"\n",
        "            })\n",
        "\n",
        "    return {\n",
        "        \"table_name\": table_name,\n",
        "        \"description\": table_description,\n",
        "        \"columns\": column_details\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1747660223827
        }
      },
      "outputs": [],
      "source": [
        "tables = db.get_usable_table_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1747660236901
        }
      },
      "outputs": [],
      "source": [
        "table_metadata=[]\n",
        "for table in tables:\n",
        "    table_metadata.append(extract_table_metadata(table))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1747660241678
        }
      },
      "outputs": [],
      "source": [
        "def clean_metadata(table_metadata):\n",
        "    for table in table_metadata:\n",
        "        table[\"columns\"] = [\n",
        "            col for col in table[\"columns\"] if col[\"name\"].strip() and col[\"name\"] != \"# Detailed Table Information\"\n",
        "        ]\n",
        "    return table_metadata\n",
        "\n",
        "clean_metadata = clean_metadata(table_metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1747660255139
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential,ManagedIdentityCredential, get_bearer_token_provider\n",
        "import openai\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# Define the required scope\n",
        "scope = \n",
        "\n",
        "# Initialize the credential\n",
        "credential = ManagedIdentityCredential()\n",
        "\n",
        "token_provider = get_bearer_token_provider(credential, scope)\n",
        "\n",
        "# Ensure you request a token with the correct scope\n",
        "token = credential.get_token(scope)\n",
        "\n",
        "client = openai.AzureOpenAI(\n",
        "    api_version=\"\",\n",
        "    azure_endpoint=\"\",\n",
        "    azure_ad_token_provider=token_provider\n",
        ")\n",
        "\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "embedding_model = AzureOpenAIEmbeddings(\n",
        "    azure_deployment=\"\",  # Set the correct Azure deployment name\n",
        "    azure_endpoint=\"\",\n",
        "    api_version=\"\",\n",
        "    azure_ad_token_provider=token_provider\n",
        ")\n",
        "\n",
        "llm_instance = AzureChatOpenAI(\n",
        "                azure_deployment=\"\",\n",
        "                api_version=\"\",\n",
        "                temperature=0,\n",
        "                max_tokens=None,\n",
        "                timeout=None,\n",
        "                #seed = azure_config.get('seed'),\n",
        "                max_retries=2,\n",
        "                azure_endpoint=\"\",\n",
        "                azure_ad_token_provider=token_provider\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1747660262527
        }
      },
      "outputs": [],
      "source": [
        "def get_embeddings(text):\n",
        "    token_provider = get_bearer_token_provider(\n",
        "    DefaultAzureCredential(), \"\"\n",
        "    )\n",
        "\n",
        "    client = AzureOpenAI(\n",
        "        api_version=\"\",\n",
        "        azure_endpoint=\"\",\n",
        "        azure_ad_token_provider=token_provider\n",
        "    )\n",
        "    response = client.embeddings.create(\n",
        "        model=\"\",\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1747660276252
        }
      },
      "outputs": [],
      "source": [
        "# Convert each table's metadata into a structured text format\n",
        "table_texts = [\n",
        "    f\"Table: {table['table_name']}\\nDescription: {table['description']}\\nColumns: {table['columns']}\"\n",
        "    for table in clean_metadata\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1747660293079
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings = np.array([get_embeddings(text) for text in table_texts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1747660301672
        }
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "# Step 3: Store embeddings in FAISS\n",
        "dimension = embeddings.shape[1]  # Get embedding dimension\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1747660317541
        }
      },
      "outputs": [],
      "source": [
        "def query_faiss(query_text):\n",
        "    query_embedding = np.array(get_embeddings(query_text)).reshape(1, -1).astype(\"float32\")  # Format for FAISS\n",
        "\n",
        "    # Perform FAISS search to find relevant tables\n",
        "    k = 3  # Number of relevant tables to retrieve\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    # Extract relevant table metadata\n",
        "    relevant_table_metadata = [table_texts[i] for i in indices[0]]\n",
        "\n",
        "    import ast\n",
        "\n",
        "    # Process metadata in a structured way\n",
        "    formatted_metadata = []\n",
        "    for data in relevant_table_metadata:\n",
        "        table_name = data.split('\\n')[0].replace('Table: ', '')\n",
        "        description = data.split('\\n')[1].replace('Description: ', '')\n",
        "\n",
        "        # Extract and parse column metadata\n",
        "        column_data_raw = data.split('Columns: ')[1]  # Extract raw column string\n",
        "        column_data = ast.literal_eval(column_data_raw)  # Convert string to Python list\n",
        "\n",
        "        # Format columns with type and description\n",
        "        columns = \"\\n\".join([\n",
        "            f\"- {col['name']} ({col['type']}): {col['description'] if col['description'] else 'No description available'}\"\n",
        "            for col in column_data\n",
        "        ])\n",
        "\n",
        "        # Append formatted metadata\n",
        "        formatted_metadata.append(f\"**Table:** {table_name}\\n**Description:** {description}\\n**Columns:**\\n{columns}\")\n",
        "\n",
        "    # Join all formatted metadata entries into a final structured text\n",
        "    context_text = \"\\n\\n\".join(formatted_metadata)\n",
        "\n",
        "    return context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1747660335965
        }
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "\n",
        "class PromptTemplate():\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "    string_template = \"\"\"\n",
        "            You are a helpful AI assistant expert in querying SQL Databases to find answers to the user's questions. \\\n",
        "        Given an input question, first create a syntactically correct {dialect} SQL query to run, then look at the results of the query and provide a meaningful, human-readable answer to the input question. \\\n",
        "        Do not return the raw SQL query result directly as the final answer. Instead, interpret the result and explain it in a concise and clear manner. \\\n",
        "        You can order the results by a relevant column to return the most interesting examples in the database. \\\n",
        "        Unless otherwise specified, do not return more than {top_k} rows. Here is the relevant table info: {table_info}\\\n",
        " \n",
        "        ===Response Guidelines\n",
        "        1. Follow these instructions for creating syntactically correct SQL queries: \\\n",
        "            - Be sure not to query for columns that do not exist in the tables and use alias only where required.\\\n",
        "            - Include unit_name, plant_name, actual_energy, daily_target_volume, and equipment_name in query if mentioned.\\\n",
        "            - Always use the column 'unit_name' associated with the unit in the generated query.\\\n",
        "            - Always use the column 'plant_name' in sql query generation whenever asked for plant or plant Names in user query. \\\n",
        "            - Always use the column 'actual_energy' associated with the energy consumption in the generated query.\\\n",
        "            - Always use the column 'daily_target_volume' associated with the production target, target volumne in the generated query.\\\n",
        "            - Always use the column 'unit_name' associated with the unit name [('Ammonia-Y1',), ('Urea-Y4',), ('Urea-Y2',), ('Mine-8',), ('Urea-Y1',), ('LNG-7',), ('Urea-Y3',), ('LNG-5',), ('Ammonia-Y3',), ('Ammonia-Y2',), ('Ammonia-Y4',), ('LNG-6',)] .\\\n",
        "            - Always use the column 'plant_name' associated with the plant name [('Y2',), ('Y3',), ('Y4',), ('Y1',)]. \\\n",
        "            - Always use the column 'equipment_name' associated with the Asset in the generated query.\\\n",
        "            - Whenever asked for plant or plant Names, return the institute names using column 'plant_name' associated with the 'plant_name' in the generated query.\\\n",
        "            - Likewise, Use appropriate aggregation functions (AVG, SUM). Use'AVG' when average word, 'SUM' when total or overall word is used. Else DO NOT use aggregate functions.\\\n",
        "            - Pay close attention to the filtering criteria mentioned in the question and incorporate them using the WHERE clause in your SQL query.\\\n",
        "            - If the question involves multiple conditions, use logical operators such as AND, OR to combine them effectively.\\\n",
        "            - When dealing with date or timestamp columns, use appropriate date functions (e.g., DATE_PART, EXTRACT) for extracting specific parts of the date or performing date arithmetic.\\\n",
        "            - If the question involves grouping of data (e.g., finding totals or averages for different categories), use the GROUP BY clause along with appropriate aggregate functions.\\\n",
        "            - Consider using aliases for tables and columns to improve readability of the query, especially in case of complex joins or subqueries.\\\n",
        "            - If necessary, use subqueries or common table expressions (CTEs) to break down the problem into smaller, more manageable parts. \\\n",
        "            - To determine the most energy-efficient or energy-inefficient plant, calculate the ratio by dividing the sum of actual production volume by the sum of actual energy used. Display the result and group along with plant namev only and unit if required. Do not apply the HAVING clause in the query.\\\n",
        "            - Incorporate filtering criteria using the WHERE clause.\\\n",
        "            - Use date functions for date or timestamp columns.\\\n",
        " \n",
        "        2. After executing the SQL query, interpret the results and provide a meaningful, human-readable answer to the user's question. \\\n",
        "            - For example, if the query returns a numeric value, explain what it represents. \\\n",
        "            - If the query returns multiple rows, summarize the key insights instead of listing all rows. \\\n",
        "            - If the query involves trends or comparisons, describe them clearly.\n",
        " \n",
        "        3. If the provided context is insufficient, explain why the query cannot be generated or why the question cannot be answered.\n",
        " \n",
        "        4. Always format the SQL query for readability before responding.\n",
        " \n",
        "        5. Always respond with a valid, well-formed JSON object in the following format:\n",
        "        {{\n",
        "            \"SQLQuery\": \"Generated SQL query here\",\n",
        "            \"SQLResult\": \"Raw SQL query result here\",\n",
        "            \"Answer\": \"Human-readable interpretation of the result here\"\n",
        "        }}\n",
        "       \n",
        "        6. If the user query is about creating graphs or plots, generate a valid SQL query to produce the data required for plotting and explain how the data can be visualized.\n",
        " \n",
        "        7. If you do not know the answer, reply as follows: {{\"answer\": \"I do not know.\"}}\n",
        " \n",
        "        ===Response Format\n",
        "        You are required to use the following format, each taking one line:\n",
        " \n",
        "        Question: Question here\n",
        "        SQLQuery: SQL Query to run\n",
        "        SQLResult: Result of the SQLQuery\n",
        "        Answer: A detailed, human-readable final answer here\n",
        "        \"\"\"\n",
        "\n",
        "    # Define your prompt template for sql query\n",
        "    sql_template = \"\"\"\n",
        "    You are a SQL expert. Given an input question, create a syntactically correct SQL query to run and return ONLY the generated Query and nothing else. \\\n",
        "    You can order the results by a relevant column to return the most interesting examples in the database. Remember NOT include backticks ```sql ``` before and after the created query. Unless otherwise specified, do not return more than \\\n",
        "    {top_k} rows. Here is the relevant table info: {table_info} \\\n",
        "    Finally, Use only tables names and Column names mentioned in:\\n\\n to create correct SQL Query and pay close attention on which column is in which table. if context contains more than one tables then create a query by performing JOIN operation for the tables.\\\n",
        "\n",
        "    ===Response Guidelines\n",
        "    1. Follow these Instructions for creating syntactically correct SQL query: \\\n",
        "        - Be sure not to query for columns that do not exist in the tables and use alias only where required.\\\n",
        "        - Always use the column 'unit_name' associated with the unit in the generated query.\\\n",
        "        - Always use the column 'actual_energy' to calculate energy consumption for the input question.\\\n",
        "        - Always use the column 'daily_target_volume' associated with the production target, target volumne in the generated query.\\\n",
        "        - Always use the column 'plant_name' in sql query generation whenever asked for plant or plant Names in user query. \\\n",
        "        - Always use the column 'unit_name'  for the unit name values 'Ammonia-Y1', 'Urea-Y4', 'Urea-Y2', 'Mine-8', 'Urea-Y1', 'LNG-7', 'Urea-Y3', 'LNG-5', 'Ammonia-Y3', 'Ammonia-Y2', 'Ammonia-Y4', 'LNG-6'.\\\n",
        "        - Always use the column 'plant_name' associated with the plant name [('Y2',), ('Y3',), ('Y4',), ('Y1',)]. \\\n",
        "        - Always use the column 'equipment_name' associated with the Asset in the generated query.\\\n",
        "        - Whenever asked for plant or plant Names, return the institute names using column 'plant_name' associated with the 'plant_name' in the generated query.\\\n",
        "        - When the user requests plant names or all plant names along with unit names, ensure that the generated query displays both plant_name and unit_name columns.\\\n",
        "        - Likewise, when asked about the average (AVG function) or ratio, ensure the appropriate aggregation function is used.\\\n",
        "        - Pay close attention to the filtering criteria mentioned in the question and incorporate them using the WHERE clause in your SQL query.\\\n",
        "        - If the question involves multiple conditions, use logical operators such as AND, OR to combine them effectively.\\\n",
        "        - When dealing with date or timestamp columns, use appropriate date functions (e.g., DATE_PART, EXTRACT) for extracting specific parts of the date or performing date arithmetic.\\\n",
        "        - If the question involves grouping of data (e.g., finding totals or averages for different categories, finding value per unit_name or plant), use the GROUP BY clause along with appropriate aggregate functions.\\\n",
        "        - Consider using aliases for tables and columns to improve readability of the query, especially in case of complex joins or subqueries.\\\n",
        "        - If necessary, use subqueries or common table expressions (CTEs) to break down the problem into smaller, more manageable parts. \\\n",
        "\n",
        "    2. If the provided context is sufficient, please generate a valid query without any explanations for the question.\n",
        "    3. If the provided context is insufficient, please explain why it can't be generated.\n",
        "    4. Please use the most relevant table(s).\n",
        "    5. you restrict 'sql_db_query' invoking with query  upto only one time. \n",
        "    6. you restrict 'sql_db_query_checker' invoking with query upto only one time.  \n",
        "    7. Please format the query before responding.\n",
        "    8. Please always respond with a valid well-formed JSON object with the following format.\n",
        "    9. If user query is about creation of graphs and plots in that case please generate a valid sql query to produce the data which will be use in ploting . \n",
        "    10. If the question does not seem related to the database, just return 'I don't know' as the answer. \n",
        "\n",
        "    ===Response Format\n",
        "    {{\n",
        "        \"query\": \"A generated SQL query when context is sufficient.\",\n",
        "        \"explanation\": \"An explanation of failing to generate the query.\"\n",
        "    }}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def define_prompt(self,template, context_text):\n",
        "        # Create a ChatPromptTemplate\n",
        "        sql_prompt = template.format(\n",
        "        dialect=db.dialect,\n",
        "        top_k=5,\n",
        "        table_info=context_text)\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "                [\n",
        "                    (\"system\", sql_prompt),\n",
        "                    (\"human\", \"{input}\"),\n",
        "                    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "                ]\n",
        "            )\n",
        "        return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1747660130455
        }
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_sql_agent\n",
        "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
        "\n",
        "\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm_instance)\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1747660131352
        }
      },
      "outputs": [],
      "source": [
        "def agent_trigger(question):\n",
        "    # Define your prompt template\n",
        "    prompt_templates = PromptTemplate()\n",
        "\n",
        "    context = query_faiss(question)\n",
        "\n",
        "\n",
        "    string_prompt = prompt_templates.define_prompt(prompt_templates.string_template, context)\n",
        "    sql_prompt = prompt_templates.define_prompt(prompt_templates.sql_template, context)\n",
        "\n",
        "    dbr_agent = create_sql_agent(\n",
        "        llm=llm_instance,\n",
        "        toolkit=toolkit,\\\n",
        "        prompt=string_prompt,\n",
        "        agent_type= \"openai-tools\",\n",
        "        handle_parsing_errors=True,\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    sql_dbr_agent = create_sql_agent(\n",
        "                llm=llm_instance,\n",
        "                toolkit=toolkit,\n",
        "                prompt=sql_prompt,\n",
        "                agent_type=\"openai-tools\",\n",
        "                handle_parsing_errors=True,\n",
        "                verbose=True,\n",
        "                max_iterations=5\n",
        "            )\n",
        "    return (dbr_agent.invoke(question),sql_dbr_agent.invoke(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1747660132790
        }
      },
      "outputs": [],
      "source": [
        "question = \"What iwas the most energy efficient plant in 2024?\"\n",
        "response  = agent_trigger(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
